{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Score Analysis for Clusters\n",
    "\n",
    "This notebook computes the balance_score and balance_scores_detailed for each cluster in cluster_categorizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add the data_pipeline package to path\n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "\n",
    "# Import the balance score calculation function\n",
    "from data_pipeline.assets.ai_conversations.utils.find_top_k_users import get_approx_user_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory\n",
    "data_dir = Path().absolute() / \"..\" / \"data\"\n",
    "\n",
    "# List available files\n",
    "print(\"Available dagster run IDs:\")\n",
    "dagster_runs = list((data_dir / \"dagster/cluster_categorizations\").glob(\"*.snappy\"))\n",
    "for run in dagster_runs:\n",
    "    print(f\"- {run.stem}\")\n",
    "\n",
    "# Choose the latest run or a specific one\n",
    "latest_run_id = dagster_runs[-1].stem if dagster_runs else None\n",
    "run_id = latest_run_id  # Change this if you want to use a specific run ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the categorized clusters data\n",
    "categorized_clusters_path = data_dir / f\"dagster/cluster_categorizations/{run_id}.snappy\"\n",
    "categorized_clusters_df = pl.read_parquet(categorized_clusters_path)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Loaded {len(categorized_clusters_df)} categorized clusters\")\n",
    "print(\"\\nColumns:\")\n",
    "print(categorized_clusters_df.columns)\n",
    "\n",
    "# Display sample rows\n",
    "categorized_clusters_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_balance_scores(embeddings_current, embeddings_other):\n",
    "    len_current = len(embeddings_current)\n",
    "    len_other = len(embeddings_other)\n",
    "    if len_other == 0 or len_current == 0:\n",
    "        return float(\"inf\"), {}  # Deprioritize if either side has no conversations\n",
    "\n",
    "    # Calculate imbalance penalty (smaller is better)\n",
    "    ratio = len_current / len_other\n",
    "    imbalance = abs(math.log(ratio))\n",
    "\n",
    "    # Calculate magnitude bonus (larger total is better)\n",
    "    total_conversations = len_current + len_other\n",
    "    magnitude_factor = 1 / total_conversations  # Inverse so smaller is better\n",
    "\n",
    "    # Calculate cosine similarity between embeddings\n",
    "    sim = get_approx_user_sim(np.array(embeddings_current), np.array(embeddings_other))\n",
    "    dist = 1 - sim\n",
    "\n",
    "    return imbalance + magnitude_factor + dist, {\n",
    "        \"imbalance\": imbalance,\n",
    "        \"magnitude_factor\": magnitude_factor,\n",
    "        \"dist\": dist,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def compute_cluster_balance_scores(df):\n",
    "    # First pass: collect all metrics\n",
    "    all_imbalances = []\n",
    "    all_magnitudes = []\n",
    "    all_distances = []\n",
    "    pair_data = []\n",
    "    \n",
    "    # Get unique clusters\n",
    "    unique_clusters = df.select(pl.col(\"cluster_id\")).unique()\n",
    "    \n",
    "    for cluster_id in unique_clusters[\"cluster_id\"]:\n",
    "        # Get conversations for this cluster\n",
    "        cluster_convos = df.filter(pl.col(\"cluster_id\") == cluster_id)\n",
    "        \n",
    "        # Get unique users in this cluster\n",
    "        users = set()\n",
    "        users.update(cluster_convos[\"user_id\"].unique().to_list())\n",
    "        \n",
    "        # For each pair of users, calculate raw metrics\n",
    "        users = list(users)\n",
    "        for i in range(len(users)):\n",
    "            for j in range(i+1, len(users)):\n",
    "                user1, user2 = users[i], users[j]\n",
    "                \n",
    "                # Get conversations for each user\n",
    "                user1_convos = cluster_convos.filter(pl.col(\"user_id\") == user1)\n",
    "                user2_convos = cluster_convos.filter(pl.col(\"user_id\") == user2)\n",
    "                \n",
    "                # Calculate raw metrics\n",
    "                if len(user1_convos) > 0 and len(user2_convos) > 0:\n",
    "                    ratio = len(user1_convos) / len(user2_convos)\n",
    "                    imbalance = abs(math.log(ratio))\n",
    "                    magnitude_factor = 1 / (len(user1_convos) + len(user2_convos))\n",
    "                    \n",
    "                    sim = get_approx_user_sim(\n",
    "                        np.array(user1_convos.get_column(\"embedding\").to_list()), \n",
    "                        np.array(user2_convos.get_column(\"embedding\").to_list())\n",
    "                    )\n",
    "                    dist = 1 - sim\n",
    "                    \n",
    "                    all_imbalances.append(imbalance)\n",
    "                    all_magnitudes.append(magnitude_factor)\n",
    "                    all_distances.append(dist)\n",
    "                    \n",
    "                    pair_data.append({\n",
    "                        \"cluster_id\": cluster_id,\n",
    "                        \"user1\": user1,\n",
    "                        \"user2\": user2,\n",
    "                        \"user1_convos\": len(user1_convos),\n",
    "                        \"user2_convos\": len(user2_convos),\n",
    "                        \"imbalance\": imbalance,\n",
    "                        \"magnitude_factor\": magnitude_factor,\n",
    "                        \"dist\": dist,\n",
    "                        \"category\": cluster_convos[\"category\"][0] if \"category\" in cluster_convos.columns else None\n",
    "                    })\n",
    "    \n",
    "    # Standardize metrics\n",
    "    scaler = StandardScaler()\n",
    "    metrics = np.column_stack([all_imbalances, all_magnitudes, all_distances])\n",
    "    standardized_metrics = scaler.fit_transform(metrics)\n",
    "    \n",
    "    # Second pass: compute standardized balance scores\n",
    "    results = []\n",
    "    for i, pair in enumerate(pair_data):\n",
    "        std_imbalance, std_magnitude, std_dist = standardized_metrics[i]\n",
    "        balance_score = std_imbalance + std_magnitude + std_dist\n",
    "        \n",
    "        result = pair.copy()\n",
    "        result[\"balance_score\"] = balance_score\n",
    "        result[\"std_imbalance\"] = std_imbalance\n",
    "        result[\"std_magnitude\"] = std_magnitude  \n",
    "        result[\"std_dist\"] = std_dist\n",
    "        results.append(result)\n",
    "    \n",
    "    return pl.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute balance scores for all clusters\n",
    "balance_scores_df = compute_cluster_balance_scores(categorized_clusters_df)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Computed balance scores for {len(balance_scores_df)} user pairs across clusters\")\n",
    "balance_scores_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if category column exists\n",
    "if \"category\" in balance_scores_df.columns:\n",
    "    # Group by category and calculate average scores\n",
    "    category_stats = balance_scores_df.group_by(\"category\").agg(\n",
    "        pl.col(\"balance_score\").mean().alias(\"avg_balance_score\"),\n",
    "        pl.col(\"imbalance\").mean().alias(\"avg_imbalance\"),\n",
    "        pl.col(\"magnitude_factor\").mean().alias(\"avg_magnitude_factor\"),\n",
    "        pl.col(\"dist\").mean().alias(\"avg_dist\"),\n",
    "        pl.len().alias(\"count\")\n",
    "    )\n",
    "    \n",
    "    # Display category statistics\n",
    "    print(\"Balance score statistics by category:\")\n",
    "\n",
    "category_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a figure with multiple plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot histograms for each component\n",
    "components = [\"imbalance\", \"magnitude_factor\", \"dist\"]\n",
    "titles = [\"Imbalance\", \"Magnitude Factor\", \"Distance\"]\n",
    "\n",
    "for i, (component, title) in enumerate(zip(components, titles)):\n",
    "    if \"category\" in balance_scores_df.columns:\n",
    "        sns.histplot(data=balance_scores_df.to_pandas(), x=component, hue=\"category\", \n",
    "                     element=\"step\", bins=20, common_norm=False, ax=axes[i])\n",
    "    else:\n",
    "        sns.histplot(data=balance_scores_df.to_pandas(), x=component, bins=20, ax=axes[i])\n",
    "    \n",
    "    axes[i].set_title(f\"Distribution of {title}\")\n",
    "    axes[i].set_xlabel(component)\n",
    "    axes[i].axvline(x=balance_scores_df[component].mean(), color='r', linestyle='--', \n",
    "                    label=f\"Mean: {balance_scores_df[component].mean():.3f}\")\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between components\n",
    "correlation_cols = [\"balance_score\", \"imbalance\", \"magnitude_factor\", \"dist\"]\n",
    "correlation_df = balance_scores_df.select(correlation_cols).to_pandas()\n",
    "\n",
    "# Plot correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_df.corr(), annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, center=0)\n",
    "plt.title(\"Correlation Between Balance Score Components\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Clusters by Balance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_scores_df.sort(\"balance_score\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook analyzed the balance scores for clusters in the categorized data. The balance score is a composite metric that combines:\n",
    "\n",
    "1. **Imbalance**: How evenly distributed conversations are between users (lower is better)\n",
    "2. **Magnitude Factor**: Inverse of total conversation count (lower means more conversations)\n",
    "3. **Distance**: Semantic distance between user conversations (lower means more similar interests)\n",
    "\n",
    "These scores help identify the most promising clusters for generating serendipitous connections between users."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}